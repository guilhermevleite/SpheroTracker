# -*- coding: utf-8 -*-
"""Segmentation_Statistical_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1H4oXo_xTgulETvInypWAQi0TsBvzm0aI
"""

from google.colab import drive
drive.mount('/content/drive')
!pip install statannotations

"""## Imports"""

from pathlib import Path
import cv2 as cv
import numpy as np
import math
import csv
import pandas as pd
from scipy.stats import tukey_hsd
import scipy.stats as stats
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import plotly
import plotly.graph_objects as go

from tqdm import tqdm
from itertools import combinations
from statannotations.Annotator import Annotator

"""# Debug Helper

**TODO** Deletar depois

*Estou usando esse cÃ³digo para descobrir o problema com o threshold dando erro*
"""

from google.colab.patches import cv2_imshow

def debug_img(image_lst, color):

    iterator = iter(image_lst)
    horizontal = next(iterator)

    if len(horizontal.shape) == 2:
        horizontal = cv.cvtColor(horizontal, cv.COLOR_GRAY2BGR)

    for image in iterator:
        if len(image.shape) == 2:
            image = cv.cvtColor(image, cv.COLOR_GRAY2BGR)

        print(horizontal.shape, image.shape)
        horizontal = cv.hconcat([horizontal, image])

        cv2_imshow(horizontal)


def colorize_connected_components(labels):
    label_hue = np.uint8(179*labels/np.max(labels))
    blank_ch = 255*np.ones_like(label_hue)
    labeled_img = cv.merge([label_hue, blank_ch, blank_ch])

    labeled_img = cv.cvtColor(labeled_img, cv.COLOR_HSV2BGR)

    labeled_img[label_hue==0] = 0

    return labeled_img

"""## Global Variables"""

# TODO : ILUSTRAR ISSO COM FIGURA OU APONTAR NO EXEMPLO
# Path to the folder of the DAYS folder.

# String GUI ðŸ¥›
CONFIG_INPUT = "/content/drive/MyDrive/spheroid_bia_segmentation/grupo_2"
# String BIA
# CONFIG_INPUT = "/content/drive/MyDrive/Mestrado/papers_em_desenvolvimento/segmentation_analysis/images_organized/grupo_2" #podemos deixar um caminho comum
# Size of the output image, 512 means the output image will be 512x512 in size.
CONFIG_OUTPUT_SIZE = 512

# Scale of one pixel, in our case one pixel is 0.8333um (micro-meters), the unit is irrelevant.
PIXEL_SCALE = 7.0175


# Number of compounds (TreaTmenT) being tested, DO NOT include control in this counter
TTT_COUNT = 3

"""## Image Loader Functions"""

def image_pre_loading(img):
    '''
    Sanity check on recently loaded pictures. If the image failed to load for some reason, a black image is returned.
    The output image is also resized to the desired output size, specified in global variable CONFIG_OUTPUT_SIZE
    '''
    if img is None:
        return np.zeros((CONFIG_OUTPUT_SIZE, CONFIG_OUTPUT_SIZE), dtype="uint8")

    return cv.resize(img, (CONFIG_OUTPUT_SIZE, CONFIG_OUTPUT_SIZE))


def get_samples_name_list(folder_list: Path) -> list:
    '''
    Returns a list with the path of all sample image, using the DAY folder as reference.

    sampling_path: Path to the folder containing the images folder of the sampling (day).
    '''

    path_first_folder = folder_list[0]
    sample_name_list: list = []

    for sample in sorted((path_first_folder / 'images').glob('*')):
        sample_name_list.append(sample)

    return sample_name_list


def get_sample_images(sample_name: str, sample_folder_list: Path) -> list:
    '''
    Loads the sample image for all listed folders, returns a list with all sample images.

    sample_name: Name of the target sample.
    sample_folder_list: List of the folders to load the sample.
    '''

    image_lst = []

    for sample_folder in sample_folder_list:
        if not sample_folder.is_dir():
            continue

        image_path = str(sample_folder / "images" / sample_name)

        if Path(image_path).exists():
            img = cv.imread(image_path, 0)
        else:
            print('WARNING, not loaded', image_path)
            img = None

        img = image_pre_loading(img)
        image_lst.append(img)

    return image_lst

"""## Segmentation Functions"""

def threshold(image):
    '''
    Applies the OTSU threshold to this image.
    Returns the resulting mask.
    '''

    img = cv.bitwise_not(image)
    _, thresh = cv.threshold(img, 0, 255, cv.THRESH_OTSU)

    return thresh

def post_processing_threshold(thresh):
    '''
    Executes some post_processing steps on top of the thresholded image.
    This steps are erode operations, to vanish with small regions created
    by the thresholding algorithm.
    Returns the resulting image.
    '''
    kernel = cv.getStructuringElement(cv.MORPH_CROSS, (3,3))

    thresh = cv.erode(thresh, kernel)
    thresh = cv.erode(thresh, kernel)
    thresh = cv.erode(thresh, kernel)

    thresh = cv.dilate(thresh, kernel)

    return thresh

"""## Connected Components Functions






"""

def find_largest_region(stats_list):
    '''
    Finds the largest region in the stats list, and returns
    its index.
    stats_list: List returned by the connectedcomponent
    analysis, again, the largest region is assumed to be the
    spheroid region.
    '''

    smallest = math.inf
    spheroid_label = -1

    for idx, region in enumerate(stats_list):
        # Index [4] is the area value
        if region[4] > stats_list[spheroid_label][4] and idx > 0 and region[0] != 0:

            spheroid_label = idx

    return spheroid_label

def get_spheroid_mask_from_thresh(segmented_list) -> tuple:
    '''
    Returns two lists, the first list containing the
    spheroid region segmentation, and a list with their
    areas.
    segmented_list: Is a list of the threshold results, with
    many connected regions. We assume that the largest
    connected region is also the spheroid region.
    '''

    mask_list = []
    area_list = []
    for idx, spheroid in enumerate(segmented_list):

        _, labels, stats, centroids = cv.connectedComponentsWithStats(spheroid)
        possible_spheroid_region_label = find_largest_region(stats)

        colorize_connected_components(labels)

        gray_image = None
        # Image is already in grayscale
        if len(spheroid.shape) < 3:
            gray_image = np.copy(spheroid)
        # Image needs to be converted to grayscale
        else:
            gray_image = cv.cvtColor(spheroid, cv.COLOR_BGR2GRAY)

        # Quantize the image
        gray_image[labels == possible_spheroid_region_label] = 255
        gray_image[labels != possible_spheroid_region_label] = 0

        mask_list.append(gray_image)
        area_list.append(stats[possible_spheroid_region_label][4])

    return mask_list, area_list

"""## Output Functions"""

def save_sample_segmentation_render(input_folder,
                                    full_path,
                                  mask_list,
                                  area_list):
    '''
    Saves the sample segmentation render results into the
    file system.
    The target folder is created next to the <images> folder,
    and is called masks.
    '''

    days = sorted(Path(input_folder).glob('*'))
    for idx, mask in enumerate(mask_list):
        if not days[idx].is_dir():
            continue

        file_name = str(full_path.name).replace('.tif', '.png')

        mask_dir = days[idx] / 'masks'
        mask_dir.mkdir(parents=True, exist_ok=True)

        cv.imwrite(str(mask_dir / file_name), mask)


def save_segmentation_csv(folder, well_list, area_list):

    with open(folder + '/areas.csv', 'w') as f:
        write = csv.writer(f)

        header = ['time', 'sample', 'area', 'experiment']
        write.writerow(header)

        for w_idx, well in enumerate(well_list):
            name = (well.name).split('.')[0]
            for day, area in enumerate(area_list[w_idx]):
                experiment = 'control'
                if 'test' in name:
                    string = name.split('_')
                    experiment = f'{string[0]}_{string[1]}'
                if area == 0:
                    row = [day, name, 'NaN', experiment]
                else:
                    row = [day, name, f'{(area * PIXEL_SCALE):.3f}', experiment]
                write.writerow(row)

"""## Segmentation Steps"""

def segmentation_method(image_list):
    '''
    Segments all images in image_list.
    Returns a list with the images masks.
    '''
    mask_list = []

    for idx, image in enumerate(image_list):
        simple_threshold = threshold(image)
        clean_threshold = post_processing_threshold(simple_threshold)

        mask_list.append(clean_threshold)

    return mask_list

"""# Main"""

# List with all the DAY folders
path_sampling_lst = sorted(Path(CONFIG_INPUT).glob("*"))
sample_list = get_samples_name_list(path_sampling_lst)
csv_table = []

# For each sample on the first folder, find it in every other folder.
for sample in tqdm(sample_list):

    # List of this SAMPLE image for every folder.
    sample_image_lst = get_sample_images(sample.name, path_sampling_lst)

    # Segmentation pipeline -
    segmented_sample_list = segmentation_method(sample_image_lst)
    spheroid_mask_list, spheroid_area_list = get_spheroid_mask_from_thresh(segmented_sample_list)

    save_sample_segmentation_render(CONFIG_INPUT,
                                    sample,
                                    spheroid_mask_list,
                                    spheroid_area_list)

    csv_table.append(spheroid_area_list)

save_segmentation_csv(CONFIG_INPUT, sample_list, csv_table)

def replace_nan_with_mean(csv_table):
    """
    Replaces NaN values in a CSV table with the mean of their pairs, ignoring the first row and ignoring the first column.

    Args:
        csv_table: A list of lists representing the CSV table.

    Returns:
        A new list of lists with NaN values replaced by the mean of their pairs.
    """

    # Get the number of rows and columns in the table.
    num_rows = len(csv_table)
    num_cols = len(csv_table[0])

    # Replaces NaN with zeros
    for i in range(num_rows):
        # Iterate over the columns, starting from the second column.
        for j in range(num_cols):
            # If the value is NaN, replace it with the mean of its pairs.
            if csv_table[i][j] == 'NaN':
                csv_table[i][j] = 0

    # Iterate over the rows, starting from the second row.
    for i in range(num_rows):
        # Iterate over the columns, starting from the second column.
        for j in range(num_cols):
            # If the value is NaN, replace it with the mean of its pairs.
            if csv_table[i][j] == 0:
                # Get the values of the pairs.

                if j == 0:
                    mean = csv_table[i][j+1] / 2
                elif j == num_cols-1:
                    mean = csv_table[i][j-1] / 2
                else:
                    pair1 = csv_table[i][j-1]
                    pair2 = csv_table[i][j+1]

                    # Calculate the mean of the pairs.
                    mean = (float(pair1) + float(pair2)) / 2

                csv_table[i][j] = mean

    return csv_table

# new_csv_table = replace_nan_with_mean(csv_table)

"""# Statistical Analysis

## Statistics related functions
"""

# Statistics will be done on top of this .csv file.
# Obs.: Rename if you want to skip the segmentation process.

df = pd.read_csv(CONFIG_INPUT + "/areas.csv")

"""## Normal distribution"""

def is_column_normal(df, column):
    '''
        Checks whether a column of the dataframe follows the normal distribution.
        Uses the Shapiro test, and threshold of p-value < 0.05

        Returns:
            - True if distribution is normal, or False otherwise.
    '''

    result = stats.shapiro(df[column])

    if result.pvalue < 0.05:
        return False
    else:
        return True

# To define experimental conditions

interval_lst = df["time"].unique()

for it in interval_lst:

    print(f'Interval {it}')

    # Get control samples
    compound_prefix = 'control_'
    control_sample_lst = df.query(f'time == {it} and sample.str.contains(@compound_prefix)')
    print(f'\tFound {len(control_sample_lst)} samples in CONTROL')

    # Get samples for each treatment
    for tto in range(TTT_COUNT):
        compound_prefix = f'test_{str(tto).zfill(2)}_'
        compound_sample_lst = df.query(f'time == {it} and sample.str.contains(@compound_prefix)')
        print(f'\tFound {len(compound_sample_lst)} samples in treatment {compound_prefix[:-1].upper()}')

"""## Remove outliers from "area" column"""

def remove_outliers(df, column):
    '''
        Removes outliers from a specific column of the dataframe.
        Uses the interquantile range method to remove outliers.
    '''

    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1

    filter = (df[column] >= Q1 - 1.5 * IQR) & (df[column] <= Q3 + 1.5 * IQR)
    new_df = df.loc[filter]

    return new_df

"""## T-Test"""

def run_ttest(df_one, df_two):
    '''
        Executes the T-Test analysis on distributions df_one VS df_two
        Significance means p-value < 0.05
    '''

    result = stats.ttest_ind(df_one, df_two)

    print(f'\tT-Test CONTROL vs {compound_prefix[:-1].upper()}')
    print(f'\t\tP-value:{result.pvalue:.5f} Significance: ', end='')

    if result.pvalue < 0.0001:
        print('YES', '*' * 4)
    elif result.pvalue < 0.001:
        print('YES', '*' * 3)
    elif result.pvalue < 0.01:
        print('YES', '*' * 2)
    elif result.pvalue < 0.05:
        print('YES', '*' * 1)
    else:
        print('NO')

    print(f'\t\tMean CONTROL: {np.mean(df_one):.2f}\n\t\tMean {compound_prefix[:-1].upper()}: {np.mean(df_two):.2f}')

"""## ANOVA test (TALVEZ COLOCAR O TUKEY AQUI NESTE BLOCO)"""

def run_anova(control_df, ttos_lst):
    result = stats.f_oneway(control_df["area"], *ttos_lst)

    print(f'\tANOVA for THIS interval')
    print(f'\t\tP-value:{result.pvalue:.5f} Significance: ', end='')

    if result.pvalue < 0.0001:
        print('YES', '*' * 4)
    elif result.pvalue < 0.001:
        print('YES', '*' * 3)
    elif result.pvalue < 0.01:
        print('YES', '*' * 2)
    elif result.pvalue < 0.05:
        print('YES', '*' * 1)
    else:
        print('NO')

    print(f'\t\tMean CONTROL: {np.mean(control_df["area"]):.2f}')

    for i, tto in enumerate(ttos_lst):
        compound_prefix = f'test_{str(i).zfill(2)}_'

        print(f'\t\tMean {compound_prefix[:-1].upper()}: {np.mean(tto):.2f}')

interval_lst = df["time"].unique()

graph_df = pd.DataFrame()

for it in interval_lst:

    print(f'\nInterval {it}', '=' * 60)

    # Get control samples
    compound_prefix = 'control_'
    control_sample_lst = df.query(f'time == {it} and sample.str.contains(@compound_prefix)')
    print(f'\tFound {len(control_sample_lst)} samples in CONTROL')

    control_sample_lst = remove_outliers(control_sample_lst, 'area')
    if not is_column_normal(control_sample_lst, 'area'):
        print('\tWARNING : Distribution NOT normal')
    print()

    graph_df = pd.concat([graph_df, control_sample_lst], ignore_index=True)

    ttos_this_interval = []
    # Get samples for each treatment
    for tto in range(TTT_COUNT):
        compound_prefix = f'test_{str(tto).zfill(2)}_'
        compound_sample_lst = df.query(f'time == {it} and sample.str.contains(@compound_prefix)')
        print(f'\tFound {len(compound_sample_lst)} samples in treatment {compound_prefix[:-1].upper()}')

        compound_sample_lst = remove_outliers(compound_sample_lst, 'area')
        if not is_column_normal(compound_sample_lst, 'area'):
            print('\tWARNING : Distribution NOT normal')

        run_ttest(control_sample_lst['area'], compound_sample_lst['area'])
        ttos_this_interval.append(compound_sample_lst['area'].to_list())

        graph_df = pd.concat([graph_df, compound_sample_lst], ignore_index=True)

        print()
    run_anova(control_sample_lst, ttos_this_interval)
    res = tukey_hsd(control_sample_lst['area'], *ttos_this_interval)
    print(f'\n\t{res}')

"""# Plotting
---
## Time interval configuration

In the code time is stored in sequential integers starting at 0 (zero). Overwrite each value to the desired outcome.
"""

graph_df.loc[graph_df["time"] == 0, "time"] = "0"
graph_df.loc[graph_df["time"] == 1, "time"] = "2"
graph_df.loc[graph_df["time"] == 2, "time"] = "4"
graph_df.loc[graph_df["time"] == 3, "time"] = "6"
graph_df.loc[graph_df["time"] == 4, "time"] = "8"
graph_df.loc[graph_df["time"] == 5, "time"] = "10"

y_axis_name = 'Area (ÂµmÂ²)'
x_axis_name = 'Days of treatment'

"""## Compound label configuration
In the code the compounds are named by the following rule:  
`control` for the control samples, and `test_x` for every compound, in which `x` increases from 0.  
To change the labels simply replace their name by the desired one.
"""

graph_df = graph_df.replace({
    'control': 'Control',
    'test_00': 'Vemurafenib 10ÂµM',
    'test_01': 'Violacein 2.5ÂµM',
    'test_02': 'Violacein 5ÂµM',
})

"""## Plotting functions"""

pd.options.plotting.backend = 'plotly'

plot = px.box(graph_df, x="time", y="area", points= 'all', color="experiment")

plot.update_layout(
    height=600,
    width=1500,
    legend_title=None,
    font=dict(size=15),
    yaxis=dict(
        title=y_axis_name,
        showgrid=True,
        gridcolor='rgb(255, 255, 255)'),
    xaxis=dict(title=x_axis_name),
    paper_bgcolor='rgb(255, 255, 255)',
    plot_bgcolor='rgb(233, 233, 233)',
    showlegend=True,
)